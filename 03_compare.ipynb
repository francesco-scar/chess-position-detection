{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875eff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "import multiprocessing as mp\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# Set multiprocessing start method to spawn for CUDA compatibility\n",
    "mp.set_start_method('spawn', force=True)\n",
    "\n",
    "# Configuration constants\n",
    "CONFIG_YAML_FOLDER = 'dataset/training/config_yamls'\n",
    "TRAINED_MODELS_FOLDER = 'runs'\n",
    "K = 4  # Number of cross-validation folds\n",
    "\n",
    "# Model configuration\n",
    "base_model = 'yolo11'\n",
    "sizes = ['n', 's', 'm', 'l'] \n",
    "models = {'_det': '', '_seg': '-seg', '_pose': '-pose'}\n",
    "extensions = ['.pt', '.yaml']\n",
    "tasks = {'_det': 'pieces', '_seg': 'board', '_pose': 'board'}\n",
    "\n",
    "# Load previous results if available\n",
    "try:\n",
    "    with open('results.json', 'r') as f:\n",
    "        results = json.load(f)\n",
    "        print('Loaded previous results from results.json')\n",
    "except Exception as e:\n",
    "    results = {}\n",
    "    print('No previous results found, starting fresh.', e)\n",
    "\n",
    "# Initialize error tracking\n",
    "try:\n",
    "    with open('errors.txt', 'r') as f:\n",
    "        errors = [line.strip() for line in f.readlines()]\n",
    "        print('Loaded previous errors from errors.txt')\n",
    "except Exception:\n",
    "    errors = []\n",
    "    print('No previous errors found, starting fresh.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbda65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolo_launcher import yolo_subprocess_val\n",
    "from positions import *\n",
    "\n",
    "def detection_metrics(base_model, model, size, ext):\n",
    "    \"\"\"\n",
    "    Calculate detection metrics for piece detection models using cross-validation.\n",
    "    \n",
    "    Args:\n",
    "        base_model: Base YOLO model name (e.g., 'yolo11')\n",
    "        model: Model variant ('_det', '_seg', '_pose')\n",
    "        size: Model size ('n', 's', 'm', 'l')\n",
    "        ext: File extension ('.pt', '.yaml')\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing averaged metrics and variance across folds\n",
    "    \"\"\"\n",
    "    metrics_list = []\n",
    "\n",
    "    for k in range(K):\n",
    "        # Construct model file path\n",
    "        model_file_name = os.path.join(\n",
    "            TRAINED_MODELS_FOLDER,\n",
    "            'pieces',\n",
    "            f'{base_model}{size}{models[model]}_k{k}_{ext[1:]}',\n",
    "            'weights/best.pt'\n",
    "        )\n",
    "        \n",
    "        # Get validation config file\n",
    "        config_yaml_path = os.path.join(\n",
    "            CONFIG_YAML_FOLDER,\n",
    "            f'fold_{k}{model}.yaml'\n",
    "        )\n",
    "        if os.path.exists(config_yaml_path):\n",
    "            val_path = config_yaml_path\n",
    "        else:\n",
    "            errors.append(f'Config YAML not found: {config_yaml_path}')\n",
    "            continue\n",
    "        # Load model and run validation to get metrics\n",
    "        if os.path.exists(model_file_name):\n",
    "            try:\n",
    "                print(f'Loading model from {model_file_name} for fold {k}')\n",
    "\n",
    "                proc = mp.Process(target=yolo_subprocess_val, args=(model_file_name, val_path))\n",
    "                proc.start()\n",
    "                proc.join()   \n",
    "\n",
    "                with open('/tmp/yolo_results.pkl', 'rb') as f:\n",
    "                    metrics = pickle.load(f)\n",
    "\n",
    "                metrics_list.append(metrics)\n",
    "            except Exception as e:\n",
    "                errors.append(f'Error processing {model_file_name} for fold {k}: {e}')\n",
    "        else:\n",
    "            errors.append(f'Model file not found: {model_file_name}')\n",
    "            continue\n",
    "\n",
    "    # Calculate mean and variance for each metric\n",
    "    map_values = [metrics.box.map for metrics in metrics_list]\n",
    "    mp_values = [metrics.box.mp for metrics in metrics_list]\n",
    "    mr_values = [metrics.box.mr for metrics in metrics_list]\n",
    "\n",
    "    avg_metrics = {\n",
    "        'mAP50-95': np.mean(map_values),\n",
    "        'mAP50-95_var': np.var(map_values, ddof=1) if len(map_values) > 1 else 0,\n",
    "        'mP': np.mean(mp_values),\n",
    "        'mP_var': np.var(mp_values, ddof=1) if len(mp_values) > 1 else 0,\n",
    "        'mR': np.mean(mr_values),\n",
    "        'mR_var': np.var(mr_values, ddof=1) if len(mr_values) > 1 else 0,\n",
    "        'best_fold': -1\n",
    "    }\n",
    "    \n",
    "    best_map = 0\n",
    "    for i in range(len(metrics_list)):\n",
    "        if metrics_list[i].box.map > best_map:\n",
    "            best_map = metrics_list[i].box.map\n",
    "            avg_metrics['best_fold'] = i\n",
    "\n",
    "    return avg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c0dadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to calculate metrics for board detection\n",
    "import json\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "from yolo_launcher import yolo_subprocess_batch\n",
    "\n",
    "ORIGINAL_DATASET_LABEL_FOLDER = 'dataset/data/' # Using json labels for semplicity\n",
    "\n",
    "def order_vertices(vertices):\n",
    "    \"\"\"Order vertices in clockwise order starting from top-left\"\"\"\n",
    "    vertices = np.array(vertices).reshape(-1, 2)\n",
    "    \n",
    "    # Find centroid\n",
    "    center = np.mean(vertices, axis=0)\n",
    "    \n",
    "    # Calculate angles from centroid\n",
    "    angles = np.arctan2(vertices[:, 1] - center[1], vertices[:, 0] - center[0])\n",
    "    \n",
    "    # Sort by angle (clockwise)\n",
    "    sorted_indices = np.argsort(angles)\n",
    "    return vertices[sorted_indices]\n",
    "\n",
    "\n",
    "def polygon_area(vertices):\n",
    "    \"\"\"Calculate area of polygon using shoelace formula\"\"\"\n",
    "    vertices = np.array(vertices)\n",
    "    n = len(vertices)\n",
    "    area = 0.0\n",
    "    for i in range(n):\n",
    "        j = (i + 1) % n\n",
    "        area += vertices[i][0] * vertices[j][1]\n",
    "        area -= vertices[j][0] * vertices[i][1]\n",
    "    return abs(area) / 2.0\n",
    "\n",
    "def clip_polygon_sutherland_hodgman(subject_polygon, clip_polygon):\n",
    "    \"\"\"Clip subject polygon by clip polygon using Sutherland-Hodgman algorithm\"\"\"\n",
    "    def inside(p, cp1, cp2):\n",
    "        return (cp2[0] - cp1[0]) * (p[1] - cp1[1]) > (cp2[1] - cp1[1]) * (p[0] - cp1[0])\n",
    "    \n",
    "    def compute_intersection(cp1, cp2, s, e):\n",
    "        dc = [cp1[0] - cp2[0], cp1[1] - cp2[1]]\n",
    "        dp = [s[0] - e[0], s[1] - e[1]]\n",
    "        n1 = cp1[0] * cp2[1] - cp1[1] * cp2[0]\n",
    "        n2 = s[0] * e[1] - s[1] * e[0]\n",
    "        n3 = 1.0 / (dc[0] * dp[1] - dc[1] * dp[0])\n",
    "        return [(n1 * dp[0] - n2 * dc[0]) * n3, (n1 * dp[1] - n2 * dc[1]) * n3]\n",
    "    \n",
    "    output_list = list(subject_polygon)\n",
    "    cp1 = clip_polygon[-1]\n",
    "    \n",
    "    for cp2 in clip_polygon:\n",
    "        input_list = output_list\n",
    "        output_list = []\n",
    "        if input_list:\n",
    "            s = input_list[-1]\n",
    "            for e in input_list:\n",
    "                if inside(e, cp1, cp2):\n",
    "                    if not inside(s, cp1, cp2):\n",
    "                        output_list.append(compute_intersection(cp1, cp2, s, e))\n",
    "                    output_list.append(e)\n",
    "                elif inside(s, cp1, cp2):\n",
    "                    output_list.append(compute_intersection(cp1, cp2, s, e))\n",
    "                s = e\n",
    "        cp1 = cp2\n",
    "    \n",
    "    return output_list\n",
    "\n",
    "def calculate_quadrilateral_iou(quad1, quad2):\n",
    "    \"\"\"Calculate IoU between two quadrilaterals\"\"\"\n",
    "    # Order vertices consistently\n",
    "    quad1_ordered = order_vertices(quad1)\n",
    "    quad2_ordered = order_vertices(quad2)\n",
    "    \n",
    "    # Find intersection using Sutherland-Hodgman clipping\n",
    "    intersection = clip_polygon_sutherland_hodgman(quad1_ordered, quad2_ordered)\n",
    "    \n",
    "    if len(intersection) < 3:\n",
    "        return 0.0\n",
    "    \n",
    "    # Calculate areas\n",
    "    area1 = polygon_area(quad1_ordered)\n",
    "    area2 = polygon_area(quad2_ordered)\n",
    "    intersection_area = polygon_area(intersection)\n",
    "    \n",
    "    # Calculate IoU\n",
    "    union_area = area1 + area2 - intersection_area\n",
    "    if union_area == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return intersection_area / union_area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def board_metrics(base_model, model, size, ext):\n",
    "    avg_metrics = {'iou': 0, 'iou_transform': 0, 'best_fold': -1}\n",
    "    best_metric = 0\n",
    "    debug_avg_metrics = {}\n",
    "    \n",
    "    # Lists to store values from all folds for variance calculation\n",
    "    all_fold_ious = []\n",
    "    all_fold_ious_transform = []\n",
    "\n",
    "    for k in range(K):\n",
    "        model_file_name = os.path.join(\n",
    "            TRAINED_MODELS_FOLDER,\n",
    "            'board',\n",
    "            f'{base_model}{size}{models[model]}_k{k}_{ext[1:]}',\n",
    "            'weights/best.pt'\n",
    "        )\n",
    "        config_yaml_path = os.path.join(\n",
    "            CONFIG_YAML_FOLDER,\n",
    "            f'fold_{k}{model}.yaml'\n",
    "        )\n",
    "        if os.path.exists(config_yaml_path):\n",
    "            with open(config_yaml_path, 'r') as file:\n",
    "                config = yaml.safe_load(file)\n",
    "                base_path = config['path']\n",
    "                val_path = config['val']\n",
    "        else:\n",
    "            errors.append(f'Config YAML not found: {config_yaml_path}')\n",
    "            return None, None\n",
    "        images_path = os.path.join(base_path, val_path, 'images')\n",
    "\n",
    "        # Get full path of images and labels listing the directory\n",
    "        images = [os.path.join(images_path, f) for f in os.listdir(images_path) if f.endswith('.png')]\n",
    "\n",
    "        # Load model once per fold\n",
    "        #model_instance = YOLO(model_file_name)\n",
    "        \n",
    "        # Process images in batches to avoid memory issues\n",
    "        batch_size = 32  # Adjust based on available GPU memory\n",
    "        fold_ious = []\n",
    "        fold_ious_transform = []\n",
    "        \n",
    "        for batch_start in range(0, len(images), batch_size):\n",
    "            batch_end = min(batch_start + batch_size, len(images))\n",
    "            batch_images = images[batch_start:batch_end]\n",
    "            \n",
    "            # Clear GPU cache before processing batch\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            # run yolo_subprocess as a separate process and wait for it to finish\n",
    "            proc = mp.Process(target=yolo_subprocess_batch, args=(model_file_name, batch_images))\n",
    "            proc.start()\n",
    "            proc.join()   \n",
    "\n",
    "            with open('/tmp/yolo_results.pkl', 'rb') as f:\n",
    "                model_results = pickle.load(f)\n",
    "\n",
    "            for i, image in enumerate(batch_images):\n",
    "                label = os.path.join(ORIGINAL_DATASET_LABEL_FOLDER, os.path.basename(image).replace('.png', '.json'))\n",
    "\n",
    "                with open(label, 'r') as f:\n",
    "                    correct_board_vert = json.load(f)['corners']\n",
    "\n",
    "                if model == '_seg':                \n",
    "                    if model_results[i].masks.xy is not None and len(model_results[i].masks.xy) > 0:\n",
    "                        # Get the original mask contours from xy coordinates\n",
    "                        mask_contours = model_results[i].masks.xy[0]\n",
    "                        \n",
    "                        # Convert to numpy array for OpenCV operations\n",
    "                        contour_points = np.array(mask_contours, dtype=np.float32)\n",
    "                        \n",
    "                        # Approximate the contour to a quadrilateral using masks.xy\n",
    "                        epsilon = 0.05 * cv2.arcLength(contour_points, True)\n",
    "                        board_vert = cv2.approxPolyDP(contour_points, epsilon, True)\n",
    "                        board_vert = board_vert.reshape(-1, 2)  # Flatten to 2D array\n",
    "                elif model == '_pose':\n",
    "                    board_vert = model_results[i].keypoints.xy[0].cpu().numpy()\n",
    "                \n",
    "                '''\n",
    "                image_bgr = cv2.imread(image)\n",
    "                image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "                approx_draw = np.array(board_vert, dtype=np.int32)\n",
    "\n",
    "                # Draw approximated quadrilateral in green\n",
    "                cv2.drawContours(image_rgb, [approx_draw], -1, (0, 255, 0), 3)\n",
    "                \n",
    "                # Save the image with both contours\n",
    "                cv2.imwrite('/tmp/contours_comparison2.png', cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR))\n",
    "                #print(f'Saved image with contours to /tmp/contours_comparison.png')\n",
    "                '''\n",
    "\n",
    "                print(f'Board vertices from model: {board_vert}')\n",
    "                print(f'Correct board vertices: {correct_board_vert}')\n",
    "\n",
    "                # Calculate standard IoU\n",
    "                iou = calculate_quadrilateral_iou(board_vert, correct_board_vert)\n",
    "                fold_ious.append(iou)\n",
    "                print(f'IoU: {iou}')\n",
    "\n",
    "                # Calculate IoU with transformation to board space\n",
    "                try:\n",
    "                    # Transform predicted vertices to board space using ground truth corners\n",
    "                    transform_matrix = calc_transform(correct_board_vert)\n",
    "                    \n",
    "                    # Apply transformation to predicted vertices\n",
    "                    board_vert_homogeneous = np.column_stack([board_vert, np.ones(len(board_vert))])\n",
    "                    transformed_pred = np.dot(transform_matrix, board_vert_homogeneous.T).T\n",
    "                    # Convert from homogeneous coordinates\n",
    "                    transformed_pred = transformed_pred[:, :2] / transformed_pred[:, 2:]\n",
    "                    \n",
    "                    # Ground truth in board space is always a unit square\n",
    "                    unit_square = np.array([[0, 0], [1, 0], [1, 1], [0, 1]])\n",
    "                    \n",
    "                    # Calculate IoU in transformed space\n",
    "                    iou_transform = calculate_quadrilateral_iou(transformed_pred, unit_square)\n",
    "                    fold_ious_transform.append(iou_transform)\n",
    "                    print(f'IoU Transform: {iou_transform}')\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f'Error calculating transform IoU: {e}')\n",
    "                    fold_ious_transform.append(0.0)\n",
    "\n",
    "            print(f'Done processing batch {batch_start // batch_size + 1}/{(len(images) + batch_size - 1) // batch_size} for fold {k}, {model}, {size}, {ext}')\n",
    "\n",
    "        # Calculate average IoU for this fold\n",
    "        if fold_ious:\n",
    "            fold_avg_iou = sum(fold_ious) / len(images)\n",
    "            fold_avg_iou_transform = sum(fold_ious_transform) / len(images)\n",
    "\n",
    "            debug_avg_metrics[f'fold_{k}'] = {\n",
    "                'iou': fold_avg_iou,\n",
    "                'iou_transform': fold_avg_iou_transform\n",
    "            }\n",
    "            \n",
    "            # Store fold averages for variance calculation\n",
    "            all_fold_ious.append(fold_avg_iou)\n",
    "            all_fold_ious_transform.append(fold_avg_iou_transform)\n",
    "            \n",
    "            avg_metrics['iou'] += fold_avg_iou\n",
    "            avg_metrics['iou_transform'] += fold_avg_iou_transform\n",
    "            \n",
    "            if fold_avg_iou_transform > best_metric:\n",
    "                best_metric = fold_avg_iou_transform\n",
    "                avg_metrics['best_fold'] = k\n",
    "    \n",
    "    # Calculate final averages and variances\n",
    "    avg_metrics['iou'] /= K\n",
    "    avg_metrics['iou_transform'] /= K\n",
    "    avg_metrics['iou_var'] = np.var(all_fold_ious, ddof=1) if len(all_fold_ious) > 1 else 0\n",
    "    avg_metrics['iou_transform_var'] = np.var(all_fold_ious_transform, ddof=1) if len(all_fold_ious_transform) > 1 else 0\n",
    "    \n",
    "    return avg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a61a1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for ext in extensions:\n",
    "        for model, model_ext in models.items():\n",
    "            task = tasks[model]\n",
    "            print(f'Processing task: {task}, model: {model}, extension: {ext}')\n",
    "            for size in sizes:\n",
    "                if task not in results:\n",
    "                    results[task] = {}\n",
    "\n",
    "                if f'{size}{model}{ext}' in results[task]:\n",
    "                    print(f'Skipping {size}{model}{ext} as it already exists in results')\n",
    "                    continue\n",
    "\n",
    "                if model == '_det':\n",
    "                    avg_metrics = detection_metrics(base_model, model, size, ext)\n",
    "                else:\n",
    "                    avg_metrics = board_metrics(base_model, model, size, ext)\n",
    "\n",
    "                results[task][f'{size}{model}{ext}'] = avg_metrics\n",
    "\n",
    "                torch.cuda.empty_cache()\n",
    "                torch.cuda.ipc_collect()\n",
    "\n",
    "                # Save results to json/pickle\n",
    "                with open('results.json', 'w') as f:\n",
    "                    json.dump(results, f, indent=4)\n",
    "                with open('errors.txt', 'w') as f:\n",
    "                    for error in errors:\n",
    "                        f.write(f'{error}\\n')\n",
    "\n",
    "    print('Errors:', errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
