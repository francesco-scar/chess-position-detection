{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "875eff5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded previous results from results.json\n",
      "Starting fresh raw_results dictionary.\n",
      "Loaded previous errors from errors.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "import multiprocessing as mp\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Set multiprocessing start method to spawn for CUDA compatibility\n",
    "mp.set_start_method('spawn', force=True)\n",
    "\n",
    "\n",
    "CONFIG_YAML_FOLDER = 'dataset/training/config_yamls'\n",
    "TRAINED_MODELS_FOLDER = 'runs'\n",
    "K = 4\n",
    "\n",
    "base_model = 'yolo11'\n",
    "sizes = ['n', 's', 'm', 'l'] \n",
    "models = {'_det': '', '_seg': '-seg', '_pose': '-pose'}\n",
    "#models = {'_seg': '-seg', '_pose': '-pose'}\n",
    "extensions = ['.pt', '.yaml']\n",
    "\n",
    "tasks = {'_det': 'pieces', '_seg': 'board', '_pose': 'board'}\n",
    "\n",
    "\n",
    "# Load previous results if available, else set empty\n",
    "try:\n",
    "    with open('results.json', 'r') as f:\n",
    "        results = json.load(f)\n",
    "        print('Loaded previous results from results.json')\n",
    "except Exception as e:\n",
    "    results = {}\n",
    "    print('No previous results found, starting fresh.', e)\n",
    "\n",
    "\n",
    "raw_results = {}\n",
    "print('Starting fresh raw_results dictionary.')\n",
    "\n",
    "try:\n",
    "    with open('errors.txt', 'r') as f:\n",
    "        errors = [line.strip() for line in f.readlines()]\n",
    "        print('Loaded previous errors from errors.txt')\n",
    "except Exception:\n",
    "    errors = []\n",
    "    print('No previous errors found, starting fresh.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fbda65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate detection metrics\n",
    "\n",
    "from yolo_launcher import yolo_subprocess_val\n",
    "\n",
    "def detection_metrics(base_model, model, size, ext):\n",
    "    metrics_list = []\n",
    "    for k in range(K):\n",
    "        model_file_name = os.path.join(\n",
    "            TRAINED_MODELS_FOLDER,\n",
    "            'pieces',\n",
    "            f'{base_model}{size}{models[model]}_k{k}_{ext[1:]}',\n",
    "            'weights/best.pt'\n",
    "        )\n",
    "        # Read val path from config YAML\n",
    "        config_yaml_path = os.path.join(\n",
    "            CONFIG_YAML_FOLDER,\n",
    "            f'fold_{k}{model}.yaml'\n",
    "        )\n",
    "        if os.path.exists(config_yaml_path):\n",
    "            val_path = config_yaml_path\n",
    "        else:\n",
    "            errors.append(f'Config YAML not found: {config_yaml_path}')\n",
    "            continue\n",
    "        # Load model and run validation to get metrics\n",
    "        if os.path.exists(model_file_name):\n",
    "            #try:\n",
    "                print(f'Loading model from {model_file_name} for fold {k}')\n",
    "\n",
    "                proc = mp.Process(target=yolo_subprocess_val, args=(model_file_name, val_path))\n",
    "                proc.start()\n",
    "                proc.join()   \n",
    "\n",
    "                with open('/tmp/yolo_results.pkl', 'rb') as f:\n",
    "                    metrics = pickle.load(f)\n",
    "\n",
    "                metrics_list.append(metrics)\n",
    "                #raw_results[f'{size}{model}{ext}_{k}'] = metrics\n",
    "\n",
    "            #except Exception as e:\n",
    "            #    errors.append(f'Error processing {file_name} for fold {k}: {e}')\n",
    "        else:\n",
    "            errors.append(f'Model file not found: {model_file_name}')\n",
    "            continue\n",
    "\n",
    "    # Calculate mean and variance for each metric\n",
    "    map_values = [metrics.box.map for metrics in metrics_list]\n",
    "    mp_values = [metrics.box.mp for metrics in metrics_list]\n",
    "    mr_values = [metrics.box.mr for metrics in metrics_list]\n",
    "\n",
    "    avg_metrics = {\n",
    "        'mAP50-95': np.mean(map_values),\n",
    "        'mAP50-95_var': np.var(map_values, ddof=1) if len(map_values) > 1 else 0,\n",
    "        'mP': np.mean(mp_values),\n",
    "        'mP_var': np.var(mp_values, ddof=1) if len(mp_values) > 1 else 0,\n",
    "        'mR': np.mean(mr_values),\n",
    "        'mR_var': np.var(mr_values, ddof=1) if len(mr_values) > 1 else 0,\n",
    "        'best_fold': -1\n",
    "    }\n",
    "    \n",
    "    best_map = 0\n",
    "    for i in range(len(metrics_list)):\n",
    "        if metrics_list[i].box.map > best_map:\n",
    "            best_map = metrics_list[i].box.map\n",
    "            avg_metrics['best_fold'] = i\n",
    "\n",
    "    return avg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f9721e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from positions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15c0dadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to calculate metrics for board detection\n",
    "import json\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "from yolo_launcher import yolo_subprocess_batch\n",
    "\n",
    "ORIGINAL_DATASET_LABEL_FOLDER = 'dataset/data/' # Using json labels for semplicity\n",
    "\n",
    "def order_vertices(vertices):\n",
    "    \"\"\"Order vertices in clockwise order starting from top-left\"\"\"\n",
    "    vertices = np.array(vertices).reshape(-1, 2)\n",
    "    \n",
    "    # Find centroid\n",
    "    center = np.mean(vertices, axis=0)\n",
    "    \n",
    "    # Calculate angles from centroid\n",
    "    angles = np.arctan2(vertices[:, 1] - center[1], vertices[:, 0] - center[0])\n",
    "    \n",
    "    # Sort by angle (clockwise)\n",
    "    sorted_indices = np.argsort(angles)\n",
    "    return vertices[sorted_indices]\n",
    "\n",
    "def polygon_area(vertices):\n",
    "    \"\"\"Calculate area of polygon using shoelace formula\"\"\"\n",
    "    vertices = np.array(vertices)\n",
    "    n = len(vertices)\n",
    "    area = 0.0\n",
    "    for i in range(n):\n",
    "        j = (i + 1) % n\n",
    "        area += vertices[i][0] * vertices[j][1]\n",
    "        area -= vertices[j][0] * vertices[i][1]\n",
    "    return abs(area) / 2.0\n",
    "\n",
    "def clip_polygon_sutherland_hodgman(subject_polygon, clip_polygon):\n",
    "    \"\"\"Clip subject polygon by clip polygon using Sutherland-Hodgman algorithm\"\"\"\n",
    "    def inside(p, cp1, cp2):\n",
    "        return (cp2[0] - cp1[0]) * (p[1] - cp1[1]) > (cp2[1] - cp1[1]) * (p[0] - cp1[0])\n",
    "    \n",
    "    def compute_intersection(cp1, cp2, s, e):\n",
    "        dc = [cp1[0] - cp2[0], cp1[1] - cp2[1]]\n",
    "        dp = [s[0] - e[0], s[1] - e[1]]\n",
    "        n1 = cp1[0] * cp2[1] - cp1[1] * cp2[0]\n",
    "        n2 = s[0] * e[1] - s[1] * e[0]\n",
    "        n3 = 1.0 / (dc[0] * dp[1] - dc[1] * dp[0])\n",
    "        return [(n1 * dp[0] - n2 * dc[0]) * n3, (n1 * dp[1] - n2 * dc[1]) * n3]\n",
    "    \n",
    "    output_list = list(subject_polygon)\n",
    "    cp1 = clip_polygon[-1]\n",
    "    \n",
    "    for cp2 in clip_polygon:\n",
    "        input_list = output_list\n",
    "        output_list = []\n",
    "        if input_list:\n",
    "            s = input_list[-1]\n",
    "            for e in input_list:\n",
    "                if inside(e, cp1, cp2):\n",
    "                    if not inside(s, cp1, cp2):\n",
    "                        output_list.append(compute_intersection(cp1, cp2, s, e))\n",
    "                    output_list.append(e)\n",
    "                elif inside(s, cp1, cp2):\n",
    "                    output_list.append(compute_intersection(cp1, cp2, s, e))\n",
    "                s = e\n",
    "        cp1 = cp2\n",
    "    \n",
    "    return output_list\n",
    "\n",
    "def calculate_quadrilateral_iou(quad1, quad2):\n",
    "    \"\"\"Calculate IoU between two quadrilaterals\"\"\"\n",
    "    # Order vertices consistently\n",
    "    quad1_ordered = order_vertices(quad1)\n",
    "    quad2_ordered = order_vertices(quad2)\n",
    "    \n",
    "    # Find intersection using Sutherland-Hodgman clipping\n",
    "    intersection = clip_polygon_sutherland_hodgman(quad1_ordered, quad2_ordered)\n",
    "    \n",
    "    if len(intersection) < 3:\n",
    "        return 0.0\n",
    "    \n",
    "    # Calculate areas\n",
    "    area1 = polygon_area(quad1_ordered)\n",
    "    area2 = polygon_area(quad2_ordered)\n",
    "    intersection_area = polygon_area(intersection)\n",
    "    \n",
    "    # Calculate IoU\n",
    "    union_area = area1 + area2 - intersection_area\n",
    "    if union_area == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return intersection_area / union_area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def board_metrics(base_model, model, size, ext):\n",
    "    avg_metrics = {'iou': 0, 'iou_transform': 0, 'best_fold': -1}\n",
    "    best_metric = 0\n",
    "    debug_avg_metrics = {}\n",
    "    \n",
    "    # Lists to store values from all folds for variance calculation\n",
    "    all_fold_ious = []\n",
    "    all_fold_ious_transform = []\n",
    "\n",
    "    for k in range(K):\n",
    "        model_file_name = os.path.join(\n",
    "            TRAINED_MODELS_FOLDER,\n",
    "            'board',\n",
    "            f'{base_model}{size}{models[model]}_k{k}_{ext[1:]}',\n",
    "            'weights/best.pt'\n",
    "        )\n",
    "        config_yaml_path = os.path.join(\n",
    "            CONFIG_YAML_FOLDER,\n",
    "            f'fold_{k}{model}.yaml'\n",
    "        )\n",
    "        if os.path.exists(config_yaml_path):\n",
    "            with open(config_yaml_path, 'r') as file:\n",
    "                config = yaml.safe_load(file)\n",
    "                base_path = config['path']\n",
    "                val_path = config['val']\n",
    "        else:\n",
    "            errors.append(f'Config YAML not found: {config_yaml_path}')\n",
    "            return None, None\n",
    "        images_path = os.path.join(base_path, val_path, 'images')\n",
    "\n",
    "        # Get full path of images and labels listing the directory\n",
    "        images = [os.path.join(images_path, f) for f in os.listdir(images_path) if f.endswith('.png')]\n",
    "\n",
    "        # Load model once per fold\n",
    "        #model_instance = YOLO(model_file_name)\n",
    "        \n",
    "        # Process images in batches to avoid memory issues\n",
    "        batch_size = 32  # Adjust based on available GPU memory\n",
    "        fold_ious = []\n",
    "        fold_ious_transform = []\n",
    "        \n",
    "        for batch_start in range(0, len(images), batch_size):\n",
    "            batch_end = min(batch_start + batch_size, len(images))\n",
    "            batch_images = images[batch_start:batch_end]\n",
    "            \n",
    "            # Clear GPU cache before processing batch\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            # Process batch of images\n",
    "            #model_results = model_instance(batch_images, device='cpu')\n",
    "\n",
    "            # run yolo_subprocess as a separate process and wait for it to finish\n",
    "            proc = mp.Process(target=yolo_subprocess_batch, args=(model_file_name, batch_images))\n",
    "            proc.start()\n",
    "            proc.join()   \n",
    "\n",
    "            with open('/tmp/yolo_results.pkl', 'rb') as f:\n",
    "                model_results = pickle.load(f)\n",
    "\n",
    "            # Store raw results for this fold\n",
    "            #if f'{size}{model}{ext}_{k}' not in raw_results:\n",
    "            #    raw_results[f'{size}{model}{ext}_{k}'] = []\n",
    "            #raw_results[f'{size}{model}{ext}_{k}'].extend(model_results)\n",
    "            \n",
    "            for i, image in enumerate(batch_images):\n",
    "                label = os.path.join(ORIGINAL_DATASET_LABEL_FOLDER, os.path.basename(image).replace('.png', '.json'))\n",
    "\n",
    "                with open(label, 'r') as f:\n",
    "                    correct_board_vert = json.load(f)['corners']\n",
    "\n",
    "                if model == '_seg':                \n",
    "                    if model_results[i].masks.xy is not None and len(model_results[i].masks.xy) > 0:\n",
    "                        # Get the original mask contours from xy coordinates\n",
    "                        mask_contours = model_results[i].masks.xy[0]\n",
    "                        \n",
    "                        # Convert to numpy array for OpenCV operations\n",
    "                        contour_points = np.array(mask_contours, dtype=np.float32)\n",
    "                        \n",
    "                        # Approximate the contour to a quadrilateral using masks.xy\n",
    "                        epsilon = 0.05 * cv2.arcLength(contour_points, True)\n",
    "                        board_vert = cv2.approxPolyDP(contour_points, epsilon, True)\n",
    "                        board_vert = board_vert.reshape(-1, 2)  # Flatten to 2D array\n",
    "                elif model == '_pose':\n",
    "                    board_vert = model_results[i].keypoints.xy[0].cpu().numpy()\n",
    "                \n",
    "                '''\n",
    "                image_bgr = cv2.imread(image)\n",
    "                image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "                approx_draw = np.array(board_vert, dtype=np.int32)\n",
    "\n",
    "                # Draw approximated quadrilateral in green\n",
    "                cv2.drawContours(image_rgb, [approx_draw], -1, (0, 255, 0), 3)\n",
    "                \n",
    "                # Save the image with both contours\n",
    "                cv2.imwrite('/tmp/contours_comparison2.png', cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR))\n",
    "                #print(f'Saved image with contours to /tmp/contours_comparison.png')\n",
    "                '''\n",
    "\n",
    "                print(f'Board vertices from model: {board_vert}')\n",
    "                print(f'Correct board vertices: {correct_board_vert}')\n",
    "\n",
    "                # Calculate standard IoU\n",
    "                iou = calculate_quadrilateral_iou(board_vert, correct_board_vert)\n",
    "                fold_ious.append(iou)\n",
    "                print(f'IoU: {iou}')\n",
    "\n",
    "                # Calculate IoU with transformation to board space\n",
    "                try:\n",
    "                    # Transform predicted vertices to board space using ground truth corners\n",
    "                    transform_matrix = calc_transform(correct_board_vert)\n",
    "                    \n",
    "                    # Apply transformation to predicted vertices\n",
    "                    board_vert_homogeneous = np.column_stack([board_vert, np.ones(len(board_vert))])\n",
    "                    transformed_pred = np.dot(transform_matrix, board_vert_homogeneous.T).T\n",
    "                    # Convert from homogeneous coordinates\n",
    "                    transformed_pred = transformed_pred[:, :2] / transformed_pred[:, 2:]\n",
    "                    \n",
    "                    # Ground truth in board space is always a unit square\n",
    "                    unit_square = np.array([[0, 0], [1, 0], [1, 1], [0, 1]])\n",
    "                    \n",
    "                    # Calculate IoU in transformed space\n",
    "                    iou_transform = calculate_quadrilateral_iou(transformed_pred, unit_square)\n",
    "                    fold_ious_transform.append(iou_transform)\n",
    "                    print(f'IoU Transform: {iou_transform}')\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f'Error calculating transform IoU: {e}')\n",
    "                    fold_ious_transform.append(0.0)\n",
    "\n",
    "            print(f'Done processing batch {batch_start // batch_size + 1}/{(len(images) + batch_size - 1) // batch_size} for fold {k}, {model}, {size}, {ext}')\n",
    "\n",
    "        # Calculate average IoU for this fold\n",
    "        if fold_ious:\n",
    "            fold_avg_iou = sum(fold_ious) / len(images)\n",
    "            fold_avg_iou_transform = sum(fold_ious_transform) / len(images)\n",
    "\n",
    "            debug_avg_metrics[f'fold_{k}'] = {\n",
    "                'iou': fold_avg_iou,\n",
    "                'iou_transform': fold_avg_iou_transform\n",
    "            }\n",
    "            \n",
    "            # Store fold averages for variance calculation\n",
    "            all_fold_ious.append(fold_avg_iou)\n",
    "            all_fold_ious_transform.append(fold_avg_iou_transform)\n",
    "            \n",
    "            avg_metrics['iou'] += fold_avg_iou\n",
    "            avg_metrics['iou_transform'] += fold_avg_iou_transform\n",
    "            \n",
    "            if fold_avg_iou_transform > best_metric:\n",
    "                best_metric = fold_avg_iou_transform\n",
    "                avg_metrics['best_fold'] = k\n",
    "    \n",
    "    # Calculate final averages and variances\n",
    "    avg_metrics['iou'] /= K\n",
    "    avg_metrics['iou_transform'] /= K\n",
    "    avg_metrics['iou_var'] = np.var(all_fold_ious, ddof=1) if len(all_fold_ious) > 1 else 0\n",
    "    avg_metrics['iou_transform_var'] = np.var(all_fold_ious_transform, ddof=1) if len(all_fold_ious_transform) > 1 else 0\n",
    "    \n",
    "    return avg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a61a1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing task: pieces, model: _det, extension: .pt\n",
      "Skipping n_det.pt as it already exists in results\n",
      "Skipping s_det.pt as it already exists in results\n",
      "Skipping m_det.pt as it already exists in results\n",
      "Skipping l_det.pt as it already exists in results\n",
      "Processing task: board, model: _seg, extension: .pt\n",
      "Skipping n_seg.pt as it already exists in results\n",
      "Skipping s_seg.pt as it already exists in results\n",
      "Skipping m_seg.pt as it already exists in results\n",
      "Skipping l_seg.pt as it already exists in results\n",
      "Processing task: board, model: _pose, extension: .pt\n",
      "Skipping n_pose.pt as it already exists in results\n",
      "Skipping s_pose.pt as it already exists in results\n",
      "Skipping m_pose.pt as it already exists in results\n",
      "Skipping l_pose.pt as it already exists in results\n",
      "Processing task: pieces, model: _det, extension: .yaml\n",
      "Skipping n_det.yaml as it already exists in results\n",
      "Skipping s_det.yaml as it already exists in results\n",
      "Skipping m_det.yaml as it already exists in results\n",
      "Skipping l_det.yaml as it already exists in results\n",
      "Processing task: board, model: _seg, extension: .yaml\n",
      "Skipping n_seg.yaml as it already exists in results\n",
      "Skipping s_seg.yaml as it already exists in results\n",
      "Skipping m_seg.yaml as it already exists in results\n",
      "Skipping l_seg.yaml as it already exists in results\n",
      "Processing task: board, model: _pose, extension: .yaml\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ce_guest/chess-position-detection/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 board, 37.1ms\n",
      "1: 448x640 1 board, 37.1ms\n",
      "2: 448x640 1 board, 37.1ms\n",
      "3: 448x640 1 board, 37.1ms\n",
      "4: 448x640 1 board, 37.1ms\n",
      "5: 448x640 1 board, 37.1ms\n",
      "6: 448x640 1 board, 37.1ms\n",
      "7: 448x640 1 board, 37.1ms\n",
      "8: 448x640 1 board, 37.1ms\n",
      "9: 448x640 1 board, 37.1ms\n",
      "10: 448x640 1 board, 37.1ms\n",
      "11: 448x640 1 board, 37.1ms\n",
      "12: 448x640 1 board, 37.1ms\n",
      "13: 448x640 1 board, 37.1ms\n",
      "14: 448x640 1 board, 37.1ms\n",
      "15: 448x640 1 board, 37.1ms\n",
      "16: 448x640 1 board, 37.1ms\n",
      "17: 448x640 1 board, 37.1ms\n",
      "18: 448x640 1 board, 37.1ms\n",
      "19: 448x640 1 board, 37.1ms\n",
      "20: 448x640 1 board, 37.1ms\n",
      "21: 448x640 1 board, 37.1ms\n",
      "22: 448x640 1 board, 37.1ms\n",
      "23: 448x640 1 board, 37.1ms\n",
      "24: 448x640 1 board, 37.1ms\n",
      "25: 448x640 1 board, 37.1ms\n",
      "26: 448x640 1 board, 37.1ms\n",
      "27: 448x640 1 board, 37.1ms\n",
      "28: 448x640 1 board, 37.1ms\n",
      "29: 448x640 1 board, 37.1ms\n",
      "30: 448x640 1 board, 37.1ms\n",
      "31: 448x640 1 board, 37.1ms\n",
      "Speed: 1.9ms preprocess, 37.1ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Board vertices from model: [[     845.11      253.88]\n",
      " [     436.95      209.68]\n",
      " [     853.35      239.86]\n",
      " [     463.23      229.27]]\n",
      "Correct board vertices: [[883, 242], [905, 738], [195, 599], [423, 185]]\n",
      "IoU: 0.02338408172831552\n",
      "IoU Transform: 0.04389990480943233\n",
      "Board vertices from model: [[     823.48      247.96]\n",
      " [     447.61      218.94]\n",
      " [     827.79      235.16]\n",
      " [      471.2      237.25]]\n",
      "Correct board vertices: [[207, 622], [408, 174], [879, 224], [909, 737]]\n",
      "IoU: 0.01926612474339402\n",
      "IoU Transform: 0.03256535452315446\n",
      "Board vertices from model: [[      822.5      240.35]\n",
      " [     429.81      220.68]\n",
      " [     828.81      230.99]\n",
      " [        450      240.53]]\n",
      "Correct board vertices: [[213, 639], [396, 182], [866, 218], [928, 721]]\n",
      "IoU: 0.019447656891615258\n",
      "IoU Transform: 0.03378341771729607\n",
      "Board vertices from model: [[     747.01      245.43]\n",
      " [     359.93      251.43]\n",
      " [     745.91       238.2]\n",
      " [     368.79      253.82]]\n",
      "Correct board vertices: [[295, 741], [319, 227], [788, 173], [995, 617]]\n",
      "IoU: 0.006561172423547215\n",
      "IoU Transform: 0.010758942689064794\n",
      "Board vertices from model: [[     826.27      222.42]\n",
      " [     388.22      210.97]\n",
      " [     832.51       221.6]\n",
      " [     400.42      223.18]]\n",
      "Correct board vertices: [[836, 215], [969, 676], [222, 664], [373, 211]]\n",
      "IoU: 0.010193902183990014\n",
      "IoU Transform: 0.021018102500683256\n",
      "Board vertices from model: [[     825.06       221.2]\n",
      " [     386.68      204.19]\n",
      " [     827.36      209.11]\n",
      " [     410.66      219.51]]\n",
      "Correct board vertices: [[229, 666], [376, 188], [850, 203], [946, 701]]\n",
      "IoU: 0.01999166445630173\n",
      "IoU Transform: 0.03598114379990194\n",
      "Board vertices from model: [[     809.38      224.88]\n",
      " [     370.27      222.04]\n",
      " [     814.68      225.12]\n",
      " [     381.49      232.06]]\n",
      "Correct board vertices: [[821, 215], [986, 652], [230, 676], [361, 224]]\n",
      "IoU: 0.008112759650588868\n",
      "IoU Transform: 0.01711357654781622\n",
      "Board vertices from model: [[     744.35      249.84]\n",
      " [     366.21      265.42]\n",
      " [     747.68      253.06]\n",
      " [     375.84      270.29]]\n",
      "Correct board vertices: [[276, 723], [329, 231], [793, 189], [999, 619]]\n",
      "IoU: 0.005818072186125478\n",
      "IoU Transform: 0.009808175505753858\n",
      "Board vertices from model: [[     781.06      224.41]\n",
      " [     368.04      234.89]\n",
      " [     781.68      219.06]\n",
      " [     371.22      239.25]]\n",
      "Correct board vertices: [[809, 169], [979, 647], [281, 728], [330, 207]]\n",
      "IoU: 0.006778252292429479\n",
      "IoU Transform: 0.010920012293687203\n",
      "Board vertices from model: [[     816.98      224.59]\n",
      " [     380.23      218.18]\n",
      " [     823.77      227.25]\n",
      " [     391.23      230.55]]\n",
      "Correct board vertices: [[219, 659], [376, 209], [840, 217], [966, 680]]\n",
      "IoU: 0.011760370370035661\n",
      "IoU Transform: 0.023574698640282783\n",
      "Board vertices from model: [[     824.46      250.48]\n",
      " [     415.67      218.42]\n",
      " [     831.47      235.24]\n",
      " [     440.94      230.71]]\n",
      "Correct board vertices: [[856, 227], [946, 702], [206, 635], [394, 201]]\n",
      "IoU: 0.019359687746203252\n",
      "IoU Transform: 0.03749318776863879\n",
      "Board vertices from model: [[     816.93      238.35]\n",
      " [     429.29      214.49]\n",
      " [      821.7      226.63]\n",
      " [     450.09       231.7]]\n",
      "Correct board vertices: [[865, 213], [929, 720], [217, 645], [392, 180]]\n",
      "IoU: 0.018613935352738597\n",
      "IoU Transform: 0.032090111051231746\n",
      "Board vertices from model: [[     841.26      234.94]\n",
      " [     426.24      214.52]\n",
      " [     845.51      223.67]\n",
      " [      450.7      232.76]]\n",
      "Correct board vertices: [[864, 213], [930, 719], [217, 645], [391, 180]]\n",
      "IoU: 0.020348197413601887\n",
      "IoU Transform: 0.03526670665673684\n",
      "Board vertices from model: [[     757.21      243.03]\n",
      " [     363.51      251.73]\n",
      " [     760.14      246.53]\n",
      " [     376.22      258.89]]\n",
      "Correct board vertices: [[261, 707], [336, 239], [793, 205], [1004, 615]]\n",
      "IoU: 0.00805161706527099\n",
      "IoU Transform: 0.015394206293047354\n",
      "Board vertices from model: [[     786.88      231.08]\n",
      " [     368.95      214.31]\n",
      " [     787.44      227.77]\n",
      " [     380.52      228.03]]\n",
      "Correct board vertices: [[246, 693], [355, 203], [828, 193], [970, 671]]\n",
      "IoU: 0.011953956535535184\n",
      "IoU Transform: 0.021273989134047957\n",
      "Board vertices from model: [[     823.86       253.1]\n",
      " [     447.16      224.52]\n",
      " [     828.56      242.89]\n",
      " [      469.4      242.53]]\n",
      "Correct board vertices: [[207, 625], [406, 179], [875, 225], [916, 732]]\n",
      "IoU: 0.01766311634118353\n",
      "IoU Transform: 0.030058936715872023\n",
      "Board vertices from model: [[     770.47      241.34]\n",
      " [      368.2      234.59]\n",
      " [     777.21      227.11]\n",
      " [     396.37      246.46]]\n",
      "Correct board vertices: [[799, 210], [1003, 621], [251, 697], [343, 238]]\n",
      "IoU: 0.019352466880857812\n",
      "IoU Transform: 0.04017193789427051\n",
      "Board vertices from model: [[     826.22      213.99]\n",
      " [     373.26      197.59]\n",
      " [     827.16      200.83]\n",
      " [     396.14      212.41]]\n",
      "Correct board vertices: [[849, 191], [945, 700], [240, 678], [368, 181]]\n",
      "IoU: 0.020624819430720018\n",
      "IoU Transform: 0.035281637258280166\n",
      "Board vertices from model: [[     814.84      228.41]\n",
      " [     379.61      220.38]\n",
      " [     821.13      229.55]\n",
      " [     391.26      232.85]]\n",
      "Correct board vertices: [[225, 666], [373, 203], [840, 211], [962, 684]]\n",
      "IoU: 0.010369489500008868\n",
      "IoU Transform: 0.019557756608721544\n",
      "Board vertices from model: [[     827.06      228.76]\n",
      " [     389.59      216.68]\n",
      " [      833.2      228.88]\n",
      " [     402.64      229.53]]\n",
      "Correct board vertices: [[841, 218], [964, 682], [218, 657], [378, 208]]\n",
      "IoU: 0.009984239719594033\n",
      "IoU Transform: 0.020025134268670773\n",
      "Board vertices from model: [[     741.13      254.43]\n",
      " [     356.42      245.14]\n",
      " [      738.4      246.81]\n",
      " [     364.15      249.54]]\n",
      "Correct board vertices: [[305, 749], [313, 222], [788, 161], [991, 619]]\n",
      "IoU: 0.007669102453359078\n",
      "IoU Transform: 0.011775241948360124\n",
      "Board vertices from model: [[     799.28      226.59]\n",
      " [     370.91       224.9]\n",
      " [     804.58      224.38]\n",
      " [     380.58      235.05]]\n",
      "Correct board vertices: [[240, 688], [356, 216], [821, 204], [982, 657]]\n",
      "IoU: 0.009461660415232338\n",
      "IoU Transform: 0.018297685368634884\n",
      "Board vertices from model: [[     777.78      225.29]\n",
      " [     365.96      208.31]\n",
      " [     780.12      222.82]\n",
      " [     376.79      222.93]]\n",
      "Correct board vertices: [[261, 708], [345, 199], [824, 180], [969, 667]]\n",
      "IoU: 0.011625032569870276\n",
      "IoU Transform: 0.019624587707183085\n",
      "Board vertices from model: [[     827.04      240.29]\n",
      " [     420.67      222.47]\n",
      " [     829.42      226.22]\n",
      " [      448.1       238.8]]\n",
      "Correct board vertices: [[859, 222], [941, 708], [210, 639], [393, 194]]\n",
      "IoU: 0.021183669178369762\n",
      "IoU Transform: 0.03936698174263572\n",
      "Board vertices from model: [[      826.3      233.31]\n",
      " [     389.02      221.01]\n",
      " [     832.58      236.21]\n",
      " [     402.02      233.29]]\n",
      "Correct board vertices: [[209, 645], [381, 221], [838, 230], [974, 670]]\n",
      "IoU: 0.012184712912981175\n",
      "IoU Transform: 0.0267069335879606\n",
      "Board vertices from model: [[     791.01      241.52]\n",
      " [     365.01      225.22]\n",
      " [     791.98      239.98]\n",
      " [      373.2       235.5]]\n",
      "Correct board vertices: [[236, 683], [361, 210], [828, 204], [974, 668]]\n",
      "IoU: 0.00871160502281488\n",
      "IoU Transform: 0.0160810848828915\n",
      "Board vertices from model: [[     823.68      237.41]\n",
      " [     444.54      212.19]\n",
      " [     828.26      222.63]\n",
      " [     468.16      230.72]]\n",
      "Correct board vertices: [[217, 636], [400, 162], [879, 211], [906, 739]]\n",
      "IoU: 0.020351843581665058\n",
      "IoU Transform: 0.03256873912369213\n",
      "Board vertices from model: [[     819.37       237.6]\n",
      " [     393.42       222.5]\n",
      " [     824.94      235.83]\n",
      " [     407.21      235.93]]\n",
      "Correct board vertices: [[214, 650], [383, 206], [846, 221], [959, 689]]\n",
      "IoU: 0.011500185001629372\n",
      "IoU Transform: 0.02247783621797921\n",
      "Board vertices from model: [[     795.61      219.05]\n",
      " [     376.96      197.36]\n",
      " [     797.31       215.1]\n",
      " [     391.82      214.73]]\n",
      "Correct board vertices: [[835, 187], [959, 682], [249, 693], [356, 191]]\n",
      "IoU: 0.014575345706459035\n",
      "IoU Transform: 0.025199499237616396\n",
      "Board vertices from model: [[     763.08      241.49]\n",
      " [     364.31      240.79]\n",
      " [     765.39      244.25]\n",
      " [     376.32         251]]\n",
      "Correct board vertices: [[259, 708], [340, 226], [804, 197], [994, 634]]\n",
      "IoU: 0.009256949348131538\n",
      "IoU Transform: 0.016832281175816585\n",
      "Board vertices from model: [[     821.47       260.8]\n",
      " [     441.21      228.42]\n",
      " [      825.7      251.45]\n",
      " [     462.45      245.68]]\n",
      "Correct board vertices: [[875, 231], [917, 730], [201, 617], [410, 185]]\n",
      "IoU: 0.01699241506255417\n",
      "IoU Transform: 0.029616877671972443\n",
      "Board vertices from model: [[     821.52      240.43]\n",
      " [     446.23      214.65]\n",
      " [     825.65      222.39]\n",
      " [     469.92       232.5]]\n",
      "Correct board vertices: [[889, 221], [891, 752], [210, 619], [412, 157]]\n",
      "IoU: 0.021800026423239333\n",
      "IoU Transform: 0.03478287606574311\n",
      "Done processing batch 1/24 for fold 0, _pose, n, .yaml\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ce_guest/chess-position-detection/venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 448x640 1 board, 37.3ms\n",
      "1: 448x640 1 board, 37.3ms\n",
      "2: 448x640 1 board, 37.3ms\n",
      "3: 448x640 1 board, 37.3ms\n",
      "4: 448x640 1 board, 37.3ms\n",
      "5: 448x640 1 board, 37.3ms\n",
      "6: 448x640 1 board, 37.3ms\n",
      "7: 448x640 1 board, 37.3ms\n",
      "8: 448x640 1 board, 37.3ms\n",
      "9: 448x640 1 board, 37.3ms\n",
      "10: 448x640 1 board, 37.3ms\n",
      "11: 448x640 1 board, 37.3ms\n",
      "12: 448x640 1 board, 37.3ms\n",
      "13: 448x640 1 board, 37.3ms\n",
      "14: 448x640 1 board, 37.3ms\n",
      "15: 448x640 1 board, 37.3ms\n",
      "16: 448x640 1 board, 37.3ms\n",
      "17: 448x640 1 board, 37.3ms\n",
      "18: 448x640 1 board, 37.3ms\n",
      "19: 448x640 1 board, 37.3ms\n",
      "20: 448x640 1 board, 37.3ms\n",
      "21: 448x640 1 board, 37.3ms\n",
      "22: 448x640 1 board, 37.3ms\n",
      "23: 448x640 1 board, 37.3ms\n",
      "24: 448x640 1 board, 37.3ms\n",
      "25: 448x640 1 board, 37.3ms\n",
      "26: 448x640 1 board, 37.3ms\n",
      "27: 448x640 1 board, 37.3ms\n",
      "28: 448x640 1 board, 37.3ms\n",
      "29: 448x640 1 board, 37.3ms\n",
      "30: 448x640 1 board, 37.3ms\n",
      "31: 448x640 1 board, 37.3ms\n",
      "Speed: 2.0ms preprocess, 37.3ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m     avg_metrics \u001b[38;5;241m=\u001b[39m detection_metrics(base_model, model, size, ext)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     avg_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mboard_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m results[task][\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m avg_metrics\n\u001b[1;32m     23\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()             \u001b[38;5;66;03m# Releases unused memory back to the GPU allocator\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 150\u001b[0m, in \u001b[0;36mboard_metrics\u001b[0;34m(base_model, model, size, ext)\u001b[0m\n\u001b[1;32m    148\u001b[0m proc \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mProcess(target\u001b[38;5;241m=\u001b[39myolo_subprocess_batch, args\u001b[38;5;241m=\u001b[39m(model_file_name, batch_images))\n\u001b[1;32m    149\u001b[0m proc\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m--> 150\u001b[0m \u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m   \n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/tmp/yolo_results.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    153\u001b[0m     model_results \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[0;32m/usr/lib64/python3.9/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_pid \u001b[38;5;241m==\u001b[39m os\u001b[38;5;241m.\u001b[39mgetpid(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a child process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a started process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_popen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[38;5;241m.\u001b[39mdiscard(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib64/python3.9/multiprocessing/popen_fork.py:43\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWNOHANG\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode\n",
      "File \u001b[0;32m/usr/lib64/python3.9/multiprocessing/popen_fork.py:27\u001b[0m, in \u001b[0;36mPopen.poll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m         pid, sts \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;66;03m# Child process not yet created. See #1731717\u001b[39;00m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;66;03m# e.errno == errno.ECHILD == 10\u001b[39;00m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for ext in extensions:\n",
    "        for model, model_ext in models.items():\n",
    "            task = tasks[model]\n",
    "            print(f'Processing task: {task}, model: {model}, extension: {ext}')\n",
    "            for size in sizes:\n",
    "                if task not in results:\n",
    "                    results[task] = {}\n",
    "                #if task not in raw_results:\n",
    "                #    raw_results[task] = {}\n",
    "\n",
    "                if f'{size}{model}{ext}' in results[task]:\n",
    "                    print(f'Skipping {size}{model}{ext} as it already exists in results')\n",
    "                    continue\n",
    "\n",
    "                if model == '_det':\n",
    "                    avg_metrics = detection_metrics(base_model, model, size, ext)\n",
    "                else:\n",
    "                    avg_metrics = board_metrics(base_model, model, size, ext)\n",
    "\n",
    "                results[task][f'{size}{model}{ext}'] = avg_metrics\n",
    "\n",
    "                torch.cuda.empty_cache()             # Releases unused memory back to the GPU allocator\n",
    "                torch.cuda.ipc_collect()\n",
    "\n",
    "                # Save results to json/pickle\n",
    "                with open('results.json', 'w') as f:\n",
    "                    json.dump(results, f, indent=4)\n",
    "                #with open('raw_results.pkl', 'wb') as f:\n",
    "                #    pickle.dump(raw_results, f)\n",
    "                with open('errors.txt', 'w') as f:\n",
    "                    for error in errors:\n",
    "                        f.write(f'{error}\\n')\n",
    "\n",
    "\n",
    "\n",
    "    print('Errors:', errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef53b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pieces': {'n_det.yaml': {'mAP50-95': 0.7929188774022546,\n",
       "   'mAP50-95_var': 3.813841688065984e-05,\n",
       "   'mP': 0.9021018835572465,\n",
       "   'mP_var': 0.00018976027400222146,\n",
       "   'mR': 0.8989336810576974,\n",
       "   'mR_var': 3.687597898782884e-05,\n",
       "   'best_fold': 3},\n",
       "  's_det.yaml': {'mAP50-95': 0.7578505285796058,\n",
       "   'mAP50-95_var': 0.0001249410657790542,\n",
       "   'mP': 0.8737722510859459,\n",
       "   'mP_var': 0.00035454527087558325,\n",
       "   'mR': 0.8747817359269584,\n",
       "   'mR_var': 0.00010461748303808935,\n",
       "   'best_fold': 3},\n",
       "  'm_det.yaml': {'mAP50-95': 0.5855185251296204,\n",
       "   'mAP50-95_var': 0.00013804764431909228,\n",
       "   'mP': 0.6997304885966344,\n",
       "   'mP_var': 0.0002543603331895298,\n",
       "   'mR': 0.7735520081163025,\n",
       "   'mR_var': 0.00012055408945112438,\n",
       "   'best_fold': 2},\n",
       "  'l_det.yaml': {'mAP50-95': 0.499388727034193,\n",
       "   'mAP50-95_var': 1.3981656068723817e-05,\n",
       "   'mP': 0.5968102409352859,\n",
       "   'mP_var': 0.0003545777726930947,\n",
       "   'mR': 0.7199859559925468,\n",
       "   'mR_var': 1.0519833338353075e-05,\n",
       "   'best_fold': 0},\n",
       "  'n_det.pt': {'mAP50-95': 0.949558507391129,\n",
       "   'mAP50-95_var': 4.1429114039465345e-07,\n",
       "   'mP': 0.9972875956714405,\n",
       "   'mP_var': 2.312761910291966e-07,\n",
       "   'mR': 0.994438567719649,\n",
       "   'mR_var': 6.519626870818685e-07,\n",
       "   'best_fold': 2},\n",
       "  's_det.pt': {'mAP50-95': 0.9685024131238827,\n",
       "   'mAP50-95_var': 2.1095739478338102e-08,\n",
       "   'mP': 0.9989583397482233,\n",
       "   'mP_var': 5.269263685243427e-08,\n",
       "   'mR': 0.997495688246422,\n",
       "   'mR_var': 1.8263302275068622e-07,\n",
       "   'best_fold': 1},\n",
       "  'm_det.pt': {'mAP50-95': 0.971115450607171,\n",
       "   'mAP50-95_var': 3.522037682081999e-07,\n",
       "   'mP': 0.9989533643143705,\n",
       "   'mP_var': 1.5428435535694788e-08,\n",
       "   'mR': 0.997893411391983,\n",
       "   'mR_var': 1.5891794498834497e-07,\n",
       "   'best_fold': 0},\n",
       "  'l_det.pt': {'mAP50-95': 0.9705609989948887,\n",
       "   'mAP50-95_var': 1.9837643726574016e-06,\n",
       "   'mP': 0.9982770165407362,\n",
       "   'mP_var': 6.908510666684486e-08,\n",
       "   'mR': 0.9973302109319918,\n",
       "   'mR_var': 6.247943903034483e-08,\n",
       "   'best_fold': 1}},\n",
       " 'board': {'m_pose.pt': {'iou': 0.8749216497453287,\n",
       "   'iou_transform': 0.8520215782716328,\n",
       "   'best_fold': 2,\n",
       "   'iou_var': 0.0006378413181805084,\n",
       "   'iou_transform_var': 0.0006162169601336065},\n",
       "  'l_pose.pt': {'iou': 0.8631201571696299,\n",
       "   'iou_transform': 0.8580700284845377,\n",
       "   'best_fold': 2,\n",
       "   'iou_var': 0.0003149704363036783,\n",
       "   'iou_transform_var': 0.0011262743382368598},\n",
       "  'n_seg.yaml': {'iou': 0.9766802176504468,\n",
       "   'iou_transform': 0.9763165651010588,\n",
       "   'best_fold': 3,\n",
       "   'iou_var': 4.668257650160991e-07,\n",
       "   'iou_transform_var': 5.103972403436191e-07},\n",
       "  's_seg.yaml': {'iou': 0.9734784879916287,\n",
       "   'iou_transform': 0.9720934530008437,\n",
       "   'best_fold': 2,\n",
       "   'iou_var': 1.3357658213760091e-06,\n",
       "   'iou_transform_var': 1.808622775507991e-06},\n",
       "  'm_seg.yaml': {'iou': 0.960867026666729,\n",
       "   'iou_transform': 0.964202948229903,\n",
       "   'best_fold': 2,\n",
       "   'iou_var': 5.450229991418944e-05,\n",
       "   'iou_transform_var': 9.163753355129439e-06},\n",
       "  'l_seg.yaml': {'iou': 0.9496992157949504,\n",
       "   'iou_transform': 0.9522287232577545,\n",
       "   'best_fold': 2,\n",
       "   'iou_var': 0.00015905909780922244,\n",
       "   'iou_transform_var': 8.089401313885462e-05},\n",
       "  's_pose.yaml': {'iou': 0.8866667904126281,\n",
       "   'iou_transform': 0.8907480043428148,\n",
       "   'best_fold': 3,\n",
       "   'iou_var': 8.50588902237896e-05,\n",
       "   'iou_transform_var': 9.890900445788289e-05},\n",
       "  'm_pose.yaml': {'iou': 0.5592681954170945,\n",
       "   'iou_transform': 0.5612683656087639,\n",
       "   'best_fold': 0,\n",
       "   'iou_var': 0.13863084597669648,\n",
       "   'iou_transform_var': 0.13932230627168593},\n",
       "  'l_pose.yaml': {'iou': 0.2970299726247113,\n",
       "   'iou_transform': 0.29283816437318544,\n",
       "   'best_fold': 1,\n",
       "   'iou_var': 0.10079264629440803,\n",
       "   'iou_transform_var': 0.09506427584060023},\n",
       "  'n_seg.pt': {'iou': 0.9776286715034043,\n",
       "   'iou_transform': 0.9765645050779668,\n",
       "   'best_fold': 0,\n",
       "   'iou_var': 4.862857403455118e-07,\n",
       "   'iou_transform_var': 8.565417283279098e-07},\n",
       "  's_seg.pt': {'iou': 0.9763138807413139,\n",
       "   'iou_transform': 0.9749561763566158,\n",
       "   'best_fold': 3,\n",
       "   'iou_var': 3.3031326761473113e-07,\n",
       "   'iou_transform_var': 1.5209095948312288e-06},\n",
       "  'm_seg.pt': {'iou': 0.9743783695751203,\n",
       "   'iou_transform': 0.9728984240045663,\n",
       "   'best_fold': 2,\n",
       "   'iou_var': 1.0578203804690797e-06,\n",
       "   'iou_transform_var': 4.958629246271915e-07},\n",
       "  'l_seg.pt': {'iou': 0.9734177116641555,\n",
       "   'iou_transform': 0.9720694496768705,\n",
       "   'best_fold': 0,\n",
       "   'iou_var': 1.8657162950410559e-07,\n",
       "   'iou_transform_var': 2.2099925156144458e-07},\n",
       "  'n_pose.pt': {'iou': 0.9590583413825802,\n",
       "   'iou_transform': 0.9572411427779761,\n",
       "   'best_fold': 1,\n",
       "   'iou_var': 1.862777170922588e-05,\n",
       "   'iou_transform_var': 2.4292737298217112e-05},\n",
       "  's_pose.pt': {'iou': 0.9415059706112542,\n",
       "   'iou_transform': 0.9383906038288669,\n",
       "   'best_fold': 0,\n",
       "   'iou_var': 3.0576303728344836e-05,\n",
       "   'iou_transform_var': 4.7541172354663566e-05},\n",
       "  'n_pose.yaml': {'iou': np.float64(0.013259060137959942),\n",
       "   'iou_transform': np.float64(0.017572630382827366),\n",
       "   'best_fold': 0,\n",
       "   'iou_var': np.float64(6.50445939612007e-05),\n",
       "   'iou_transform_var': np.float64(7.254257988486007e-05)}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
